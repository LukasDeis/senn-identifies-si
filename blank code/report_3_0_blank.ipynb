{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.289130Z",
     "iopub.status.busy": "2020-09-17T01:33:34.288557Z",
     "iopub.status.idle": "2020-09-17T01:33:34.290255Z",
     "shell.execute_reply": "2020-09-17T01:33:34.290746Z"
    },
    "id": "2mapZ9afGJ69"
   },
   "outputs": [],
   "source": [
    "##### Copyright 2021 Lukas Deis.\n",
    "\n",
    "# This work is licensed under the\n",
    "# Attribution-NonCommercial 3.0 Unported (CC BY-NC 3.0) License.\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://creativecommons.org/licenses/by-nc/3.0/legalcode\n",
    "#\n",
    "# A human readable summary of the License is available at\n",
    "#\n",
    "# https://creativecommons.org/licenses/by-nc/3.0/\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjFbdBldyEqf"
   },
   "source": [
    "## Install and Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:34.295537Z",
     "iopub.status.busy": "2020-09-17T01:33:34.294862Z",
     "iopub.status.idle": "2020-09-17T01:33:35.675952Z",
     "shell.execute_reply": "2020-09-17T01:33:35.675219Z"
    },
    "id": "S_BdyQlPjfDW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In a normal environment the following will install all necessary packages:\n",
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow #if posible use -gpu\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "!pip install datetime\n",
    "!pip install packaging\n",
    "!pip install keras\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this specific environment everything was installed like this:\n",
    "from local_package_installer.local_package_installer import install_local\n",
    "\n",
    "install_local('sklearn')\n",
    "install_local('pandas')\n",
    "#install_local('tensorflow')\n",
    "#install_local('pydot')\n",
    "#install_local('pydotplus')\n",
    "#install_local('graphviz')\n",
    "install_local('datetime')\n",
    "install_local('packaging')\n",
    "install_local('keras')\n",
    "install_local('numpy==18.4')\n",
    "install_local('tensorflow-gpu') #tensorflow-gpu\n",
    "install_local(\"pyreadstat==1.0.5\") # this one required me to manually copy a dll to a different location\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#using this function:\n",
    "#Run following commands in your Python session (only once per virtual machine per Python\n",
    "# version/environment):\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def installer_local(package):\n",
    "    try:\n",
    "        print('Installing local package installer.')\n",
    "        call = [sys.executable, '-m', 'pip', 'install', '--user', '--upgrade',\\\n",
    "                '--trusted-host=drefilesrv01.researchenvironment.org',\\\n",
    "                '--index-url=http://drefilesrv01.researchenvironment.org/PythonInstaller/',\\\n",
    "                package]\n",
    "        process = subprocess.Popen(call, stdin=subprocess.PIPE, stdout=subprocess.PIPE,\\\n",
    "                                   stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if process.poll() is not None:\n",
    "                break\n",
    "            if any(re.findall(r'error', output.strip(), re.IGNORECASE)):\n",
    "                raise Exception\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        print('Even if the package is installed, you possibly have to restart Python before you '\\\n",
    "              'can import the module.')\n",
    "    except:\n",
    "        print('Package could not be installed.')\n",
    "\n",
    "installer_local('pip')\n",
    "installer_local('local_package_installer')\n",
    "\n",
    "#Run following commands in your Python session (per Python session):\n",
    "from local_package_installer.local_package_installer import install_local\n",
    "\n",
    "#Examples, remove the hashtag and run the command. Replace the package\n",
    "#name (and version if applicable) for the package you want to install:\n",
    "#install_local('numpy')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install for graph: https://graphviz.gitlab.io/download/\n",
    "maybe follow: https://bobswift.atlassian.net/wiki/spaces/GVIZ/pages/131924165/Graphviz+installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from datetime import datetime\n",
    "import tensorboard\n",
    "import pyreadstat\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to see if your computer can utilize its GPU to speed everything up, let's take a look at how many GPUs are available\n",
    "# if you installed tensorflow-gpu and all necessary CUDA toolkits and drivers it should be at least one\n",
    "# If you feel like you should see more then you are, try looking at the console in which Jupyter is running\n",
    "# it might give you an information about which cuda DLLs are missing. \n",
    "# Often they end on the version of CUDA you're missing\n",
    "# Yes, sometimes them seem ancient.\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvBvobayEqi"
   },
   "source": [
    "## Reading in the data\n",
    "\n",
    "The data is read into a pandas dataframe\n",
    "\n",
    "Again:\\\n",
    "As the real data is sensitive, large and expensive to use,\n",
    "for now I use a dummy dataset about adoption-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.197790Z",
     "iopub.status.busy": "2020-09-17T01:33:42.197028Z",
     "iopub.status.idle": "2020-09-17T01:33:42.321623Z",
     "shell.execute_reply": "2020-09-17T01:33:42.320979Z"
    },
    "id": "qJ4Ajn-YyEqj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_file = 'C:/Users/Lukas.Deis/Documents/dataset/MIND_Set_Data_exported.csv'\n",
    "# convert to csv\n",
    "dataframe = pd.read_csv(data_file)\n",
    "#dataframe = dataframe.replace(np.nan,\"UNKNOWN\")\n",
    "\n",
    "print('-----------')\n",
    "#for typ in dataframe.dtypes:\n",
    "    #print(typ.?)\n",
    "    #get column name of each non object column and convert to string?\n",
    "print('-----------')\n",
    "\n",
    "#Alternative way to read things, less intuitive, other customization-options\n",
    "#dataframe, meta = pyreadstat.read_sav(data_file,user_missing=True, apply_value_formats=False)\n",
    "#print(meta.missing_ranges[\"AQ50q1\"])\n",
    "\n",
    "#If I use the second method with apply_value_formats=False all numerical ones should be fine and I have to only interpret the two dates and strings manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.343796Z",
     "iopub.status.busy": "2020-09-17T01:33:42.343010Z",
     "iopub.status.idle": "2020-09-17T01:33:42.352803Z",
     "shell.execute_reply": "2020-09-17T01:33:42.353374Z"
    },
    "id": "3uiq4hoIGyXI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zDbrozyEqq"
   },
   "source": [
    "## Creating the target variable\n",
    "\n",
    "I have to select the variable I want to train for and drop the columns that are not important or contain that information from the normal dataset.\n",
    "\n",
    "Valid for the example data:\n",
    "The task in the Kaggle competition was to predict the speed at which a pet will be adopted (e.g., in the first week, the first month, the first three months, and so on). Let's simplify this for our purposes. It is transformed into a binary classification problem:\n",
    "I simply predict whether the pet was adopted, or not.\n",
    "\n",
    "After modifying the label column, \n",
    "0 will indicate the person does not experience suicidal ideation, \n",
    "1 will indicate it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.358975Z",
     "iopub.status.busy": "2020-09-17T01:33:42.358305Z",
     "iopub.status.idle": "2020-09-17T01:33:42.365151Z",
     "shell.execute_reply": "2020-09-17T01:33:42.364619Z"
    },
    "id": "wmMDc46-yEqq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "target = \"OQ_8\" \n",
    "string_targets = dataframe[target]\n",
    "severity_sorting = { #TODO do these values make sense?\n",
    "    \"Nooit\": 0.0,\n",
    "    \"Zelden\": 0.25,\n",
    "    \"Soms\": 0.5,\n",
    "    \"Vaak\": 0.75,\n",
    "    \"Bijna altijd\": 1\n",
    "}\n",
    "\n",
    "\n",
    "target_float = string_targets.map(severity_sorting)\n",
    "target_categorical = np.where(target_float > severity_sorting[\"Nooit\"], 1, 0)\n",
    "dataframe['target'] = target_categorical # TODO this is now simple classification (0 or 1) but it could be more defined, would that not be better?\n",
    "\n",
    "# Drop un-used columns. (including our now target which can not be used for training)\n",
    "unused_cols = [target]\n",
    "dataframe = dataframe.drop(columns=unused_cols)\n",
    "\n",
    "# Patients that did not answer the target question can not be evaluated and are thus removed.\n",
    "dataframe = dataframe[dataframe['target'].notna()]\n",
    "\n",
    "\n",
    "tf.print(\"targets:\", dataframe['target'])\n",
    "#TODO note this in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To preprocess the input into usable data, we need to know which column contains what kind of data.\n",
    "# Data can either be:\n",
    "#     - a scalar value (a fee one has to pay)\n",
    "#     - a numeric value that should be interpreted as categorical (age in groups)\n",
    "#     - a string that should be interpreted as categorical ( very,a bit, not really, no)\n",
    "# Usually not everything is encoded that nicely, in this dataset there are some dates that can not easily be converted.\n",
    "#     - columns with type date need to be converted to a value of age (in years) and then sorted into categories, before further processing as categorical, numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read different types for coulumns to treat them accordingly\n",
    "# TODO read the headers from headers.csv here and remove the old hardcoded keys\n",
    "numerical_features = []\n",
    "categorical_int_features = []\n",
    "categorical_cols = [] \n",
    "date_cols = []\n",
    "year_cols = []\n",
    "to_be_removed = []\n",
    "headers_loc = 'C:/Users/Lukas.Deis/Documents/dataset/headers.csv'\n",
    "headers = pd.read_csv(headers_loc) # TODO I should use a JSON file for this\n",
    "\n",
    "headers.pop(\"notes\")\n",
    "type_sorting = { # todo, this should be stored in a JSON file instead of code\n",
    "    \"date\": date_cols,\n",
    "    \"year\": year_cols,\n",
    "    \"skalar\": numerical_features,\n",
    "    \"categorical_int\": categorical_int_features,\n",
    "    \"categorical_string\": categorical_cols, \n",
    "    \"remove\": to_be_removed # cols like id's and the date of the test that don't actually carry information for the prediction\n",
    "}\n",
    "\n",
    "for row in headers.itertuples(): # TODO can I iterate through a df like that?\n",
    "    heading, col_type = row.heading, row.type\n",
    "    # the target variable, should not be sorted as it is removed from the dataset earlier.\n",
    "    if heading == target:\n",
    "        print(row)\n",
    "        pass\n",
    "    right_column_list = type_sorting.get(col_type, lambda: tf.print(\"invalid type:\", col_type, \" for column:\", heading)) # find the type of this key #TODO fix that instead of a lambda, the error message is give, otherwise this leads to: \"AttributeError: 'function' object has no attribute 'append'\" later on\n",
    "    try:\n",
    "        right_column_list.append(heading) # append the key to the right col\n",
    "    except:\n",
    "        tf.print(\"ERROR: Something went wrong while reading the headers.csv file\")\n",
    "        tf.print(\"       Could it be that '\", col_type, \"' is not actually a valid type for a heading? It is used in row: \", heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to look at a specific list of columns, the corresponding name just needs to be uncommented\n",
    "tf.print(\n",
    "    #target\n",
    "    #numerical_features\n",
    "    #categorical_int_features\n",
    "    #categorical_cols\n",
    "    #date_cols\n",
    "    #year_cols\n",
    "    #to_be_removed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age and date columns are easiet to work with if they are in time-format. \n",
    "# Thus the columns are converted to time since [date / year] and added to the categorical_int_features as ages in years\n",
    "for date_col in date_cols:\n",
    "    # convert to years\n",
    "    dataframe[date_col] = dataframe[date_col].replace(' ',np.nan, regex=True) #replace empty strings with parsable NaN\n",
    "    dataframe[date_col] = pd.to_datetime(dataframe[date_col], format='%m/%d/%Y') # convert to date format\n",
    "    dataframe[date_col] = pd.DatetimeIndex(dataframe[date_col]).year# take only year of date\n",
    "    # add to year cols\n",
    "    year_cols.append(date_col)\n",
    "    \n",
    "for year_col in year_cols:\n",
    "    current_year = 2020\n",
    "    dataframe[year_col] = dataframe[year_col].replace(' ',np.nan, regex=True) #replace empty strings with parsable NaN\n",
    "    dataframe[year_col] = current_year - dataframe[year_col].astype(float)\n",
    "    # remove NaN values as they would break further computations\n",
    "    # this bears the risk of seeing factors in the wrong way, 0 can mean: always, never, don't know...\n",
    "    dataframe[year_col] = dataframe[year_col].replace(np.nan,0, regex=True) \n",
    "    # add to categorical_int features because that is what ages are\n",
    "    categorical_int_features.append(year_col)\n",
    "    print(dataframe[year_col])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_int_features are all ages\n",
    "# while age in general is important, small differences in age max cause more confusion than clarity\n",
    "# 20 VS 40 should be considered by the network, 20 VS 21 not so much\n",
    "# age should be considered in categories of age-groups, but the network can figure all that out for itself\n",
    "# for simplicity, age will considered as a normal numeric value, any complex relationship to the outcome should be learned\n",
    "\n",
    "# It happens that all categorical_ints in this set are ages and none are left afterwards\n",
    "# If that was different, one would need to do this differently\n",
    "# TODO make a different tag \"age\" that can be used or just mark ages as skalars\n",
    "numerical_features.extend(categorical_int_features)\n",
    "categorical_int_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.dtypes\n",
    "# make numerical columns readable as floats\n",
    "for feature in numerical_features:\n",
    "    dataframe[feature] = dataframe[feature].replace(' ',0, regex=True) # used to be np.NaN, but that does not work too well\n",
    "    dataframe[feature] = dataframe[feature].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cells that should not be considered (generalizable (long texts) or do not carry value (ID's))\n",
    "dataframe = dataframe.drop(columns=to_be_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp0NCbswyEqs"
   },
   "source": [
    "## Spliting the dataframe into train, validation, and test\n",
    "\n",
    "The loaded dataset was a single file. It has to be split into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.370622Z",
     "iopub.status.busy": "2020-09-17T01:33:42.369987Z",
     "iopub.status.idle": "2020-09-17T01:33:42.377950Z",
     "shell.execute_reply": "2020-09-17T01:33:42.378325Z"
    },
    "id": "qT6HdyEwyEqt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.25)\n",
    "train, val = train_test_split(train, test_size=0.1)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To tackle the class implanace, the minority-class will be oversampled\n",
    "# separate the two classes\n",
    "# S_I = Suicidal Ideation\n",
    "do_experience_S_I = train[train.target==1]\n",
    "do_not_experience_S_I = train[train.target==0]\n",
    "\n",
    "tf.print(\"Number of samples that DO experience suicidal ideation\", len(do_experience_S_I))\n",
    "tf.print(\"Number of samples that do NOT experience suicidal ideation\", len(do_not_experience_S_I))\n",
    "\n",
    "upsampled_do_experience_S_I = resample(\n",
    "    do_experience_S_I,\n",
    "    replace=True, # sampling WITH replacement\n",
    "    n_samples=len(do_not_experience_S_I), #so the ammount of samples is the same for both classes\n",
    "    random_state=35 # so the results are reproducable (like seed)\n",
    "    )\n",
    "\n",
    "#overwrite the old dataframe with the new, balanced one\n",
    "balanced_frame = pd.concat([upsampled_do_experience_S_I, do_not_experience_S_I])\n",
    "train = balanced_frame\n",
    "print(\"after resampling, the number of targets is balanced:\")\n",
    "tf.print(train.target.value_counts())\n",
    "#TODO note this in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_7uVu-xyEqv"
   },
   "source": [
    "## Input pipeline\n",
    "\n",
    "The dataframe is wrapped with [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "This is done to easily shuffle and batch the data. \n",
    "\n",
    "If the RAM is not sufficient, tf.data could be used directly to read it from disk in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:42.383853Z",
     "iopub.status.busy": "2020-09-17T01:33:42.383254Z",
     "iopub.status.idle": "2020-09-17T01:33:42.385369Z",
     "shell.execute_reply": "2020-09-17T01:33:42.384906Z"
    },
    "id": "7r4j-1lRyEqw",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=1):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('target')\n",
    "    \n",
    "    #tf.print(dataframe.dtypes) #[539 rows x 396 columns] when including dates\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    \n",
    "    #ds = tf.data.Dataset.from_tensor_slices((values, labels.values))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYxIXH579uS9"
   },
   "source": [
    "The general pipeline for input is finished here.\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.803710Z",
     "iopub.status.busy": "2020-09-17T01:33:42.388965Z",
     "iopub.status.idle": "2020-09-17T01:33:43.830128Z",
     "shell.execute_reply": "2020-09-17T01:33:43.830540Z"
    },
    "id": "tYiNH-QI96Jo",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.836836Z",
     "iopub.status.busy": "2020-09-17T01:33:43.836165Z",
     "iopub.status.idle": "2020-09-17T01:33:43.891242Z",
     "shell.execute_reply": "2020-09-17T01:33:43.890630Z"
    },
    "id": "nFYir6S8HgIJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()), \"\\n\")\n",
    "print('A batch of PTSDFinal:', train_features['PTSDFinal'], \"\\n\")\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqHWW54Hmte"
   },
   "source": [
    "The dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v50jBIuj4gb"
   },
   "source": [
    "## Preprocessing layers\n",
    "\n",
    "I will have to adapt the pipelines when I replace the dummy-code, but afterwards I will be able to input plain string data etc from new data as well.\n",
    "\n",
    "Information about the pre-processing layers for easy access when I am there:\n",
    "\n",
    "*   [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) - Feature-wise normalization of the data.\n",
    "*   [`CategoryEncoding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding) - Category encoding layer.\n",
    "*   [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup) - Maps strings from a vocabulary to integer indices.\n",
    "*   [`IntegerLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup) - Maps integers from a vocabulary to integer indices.\n",
    "\n",
    "A list of available preprocessing layers can be found [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXBSxnT66o8"
   },
   "source": [
    "### Numeric columns\n",
    "A Normalization() layer ensures that each numeric feature has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OosUh4kTsK_q"
   },
   "source": [
    "The `get_normalization_layer` function returns a keras layer.\n",
    "It applies featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.896825Z",
     "iopub.status.busy": "2020-09-17T01:33:43.896137Z",
     "iopub.status.idle": "2020-09-17T01:33:43.898143Z",
     "shell.execute_reply": "2020-09-17T01:33:43.898564Z"
    },
    "id": "D6OuEKMMyEq1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:43.903065Z",
     "iopub.status.busy": "2020-09-17T01:33:43.902172Z",
     "iopub.status.idle": "2020-09-17T01:33:44.842415Z",
     "shell.execute_reply": "2020-09-17T01:33:44.842862Z"
    },
    "id": "MpKgUDyk69bM",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" old example\n",
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWY00YBUx9N"
   },
   "source": [
    "TODO: If I will indeed have many numeric features (hundreds, or more), it would be more efficient to concatenate them first and use a single [normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVD--2WZ7vmh"
   },
   "source": [
    "### Categorical columns\n",
    "\n",
    "In the dummy dataset, Type is represented as a string (e.g. 'Dog', or 'Cat'). Sadly, one can not feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWlkOPwMsxdv"
   },
   "source": [
    "The `get_category_encoding_layer` function returns a layer, mapping values from a vocabulary to integer indices and one-hot encodes the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:44.850381Z",
     "iopub.status.busy": "2020-09-17T01:33:44.847119Z",
     "iopub.status.idle": "2020-09-17T01:33:44.851920Z",
     "shell.execute_reply": "2020-09-17T01:33:44.852447Z"
    },
    "id": "GmgaeRjlDoUO",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = feature_ds.map(index)\n",
    "\n",
    "  # Learn the space of possible indices.\n",
    "  encoder.adapt(feature_ds)\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiE0glOPkMyh"
   },
   "source": [
    "## Choosing and preparing columns to use\n",
    "\n",
    "While we can deal with all types of data, we have to make a list of all columns for each type.\\\n",
    "That way I am able to define which layer needs to be treated how\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.142976Z",
     "iopub.status.busy": "2020-09-17T01:33:46.123925Z",
     "iopub.status.idle": "2020-09-17T01:33:46.180021Z",
     "shell.execute_reply": "2020-09-17T01:33:46.180497Z"
    },
    "id": "Rcv2kQTTo23h",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.190642Z",
     "iopub.status.busy": "2020-09-17T01:33:46.186870Z",
     "iopub.status.idle": "2020-09-17T01:33:46.368301Z",
     "shell.execute_reply": "2020-09-17T01:33:46.368852Z"
    },
    "id": "Q3RBa51VkaAn",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "##bookkeeping for interpretation\n",
    "output_sizes = {}\n",
    "\n",
    "# Numeric features.\n",
    "for header in numerical_features:  # TODO use all headers in UMC set minus the ones I know are something else\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)\n",
    "    output_sizes[header] = encoded_numeric_col.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.379746Z",
     "iopub.status.busy": "2020-09-17T01:33:46.378953Z",
     "iopub.status.idle": "2020-09-17T01:33:46.551415Z",
     "shell.execute_reply": "2020-09-17T01:33:46.550766Z"
    },
    "id": "1FOMGfZflhoA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "\n",
    "# TODO at the UMC data, this will be more common, some tests have a categorical scale \n",
    "# However, most of them can just be interpreted as normal numerical feature, so I won't have to overdo it\n",
    "\n",
    "# Numeric features.\n",
    "for header in categorical_int_features:  \n",
    "    print(header)\n",
    "    num_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "    encoding_layer = get_category_encoding_layer(header, train_ds, dtype='int64',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_col = encoding_layer(num_col)\n",
    "    all_inputs.append(num_col)\n",
    "    encoded_features.append(encoded_col)\n",
    "    output_sizes[header] = encoded_col.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:46.561248Z",
     "iopub.status.busy": "2020-09-17T01:33:46.560569Z",
     "iopub.status.idle": "2020-09-17T01:33:48.254306Z",
     "shell.execute_reply": "2020-09-17T01:33:48.254765Z"
    },
    "id": "K8C8xyiXm-Ie",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "#TODO include progress-bar\n",
    "categorical_cols.remove(target)\n",
    "for header in categorical_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5) # TODO maybe, this line has to be duplicated and slightly changed to accomodate for different max_tokens\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)\n",
    "    output_sizes[header] = encoded_categorical_col.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Currently I do not think the UMC data needs to be balanced.\n",
    "# It will be evaluated on the same dataset (though a different part of it)\n",
    "# We do not have a large number of samples that are underrepresented, probably causing large inaccura\n",
    "\n",
    "#use:\n",
    "#    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHSnhz2fyEq3"
   },
   "source": [
    "## The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# The first step towards a working model\n",
    "# is our preprocessed input.\n",
    "# As that is a relative complex task, that is regarded it's owy model.\n",
    "\n",
    "preprocessed_layers = layers.Concatenate()(encoded_features) #encoded_features\n",
    "preprocesessing_model = tf.keras.Model(all_inputs, preprocessed_layers)\n",
    "preprocesessing_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the models structure, there are repetetive patterns.\n",
    "\n",
    "For readability those layers are combined into custom layers and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A combination of layers, common in the parameterizer\n",
    "\n",
    "class ParameterizerLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, out_shape, dropout_rate):\n",
    "        super(ParameterizerLayer, self).__init__()\n",
    "        self.para_lin = layers.Dense(out_shape, activation='linear')\n",
    "        self.para_drop = layers.Dropout(dropout_rate)\n",
    "        self.para_relu = layers.Dense(out_shape, activation=tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor,  training=False):\n",
    "        x = self.para_lin(input_tensor)\n",
    "        if training:\n",
    "            x = self.para_drop(x, training=training)\n",
    "        x = self.para_relu(x)        \n",
    "        return x\n",
    "    \n",
    "# should minimize robustness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functional model def\n",
    "\n",
    "#TODO no more static sizes\n",
    "batch_size = 1\n",
    "preprocessed_inputs_shape = 1924 #TODO why does this change???\n",
    "dropout_rate=0.1\n",
    "hidden_sizes = [200, 100, 50, 50]  # TODO fix this to actual size\n",
    "out_shape = preprocessed_inputs_shape\n",
    "\n",
    "input_shape = [batch_size, preprocessed_inputs_shape]\n",
    "input_layer = layers.Input(batch_shape = input_shape)\n",
    "\n",
    "x = input_layer\n",
    "###Parameterizer###\n",
    "x = ParameterizerLayer(hidden_sizes[0], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[1], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[2], dropout_rate)(x)\n",
    "x = ParameterizerLayer(hidden_sizes[3], dropout_rate)(x)\n",
    "x = layers.Dense(out_shape, activation='linear')(x)\n",
    "relevances = layers.Dropout(rate=dropout_rate, name=\"relevances\")(x)\n",
    "\n",
    "###Conceptizer###\n",
    "concepts = layers.Lambda(lambda t: t, name=\"concepts\")(input_layer)\n",
    "\n",
    "###Aggregator###\n",
    "\n",
    "aggregated = layers.multiply([relevances, concepts])\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.backend.sum(t, axis=-1))(aggregated)\n",
    "aggregated = layers.Lambda(lambda t: tf.keras.activations.sigmoid(t), name=\"output\")(aggregated)\n",
    "\n",
    "out_layer = [aggregated, concepts, relevances]\n",
    "\n",
    "functional_model = tf.keras.Model(inputs=input_layer, outputs=out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom fun with more inputs\n",
    "\n",
    "def get_custom_loss(some_other_argument):\n",
    "    \n",
    "    def custom_loss(y_true, y_pred): \n",
    "        loss = 0\n",
    "        loss = loss + some_other_argument\n",
    "        loss = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        return loss\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_loss(y_true, y_pred):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = {\n",
    "    \"relevances\": keras.losses.mean_absolute_error, #get_custom_loss(some_other_argument=1),\n",
    "    \"output\": keras.losses.binary_crossentropy, #tf.nn.log_poisson_loss,\n",
    "    #\"concepts\": zero_loss\n",
    "}\n",
    "\n",
    "functional_model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=loss_dict,\n",
    "    loss_weights=[1, 5, 0],\n",
    "    metrics= ['accuracy']\n",
    ")  \n",
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_train_ds = train_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), # TODO this breaks if the batch-size is anything but 1 \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in processed_train_ds.enumerate():\n",
    "    tf.print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwanted points: ['record_id', 'Volgnummer', 'InformedConsent', 'SD_0', 'SD_1', 'SD_2b', 'SD_14']\n",
    "# Some of them should indeed have been removed from the model, \n",
    "# some are dates that still need to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:48.331722Z",
     "iopub.status.busy": "2020-09-17T01:33:48.330973Z",
     "iopub.status.idle": "2020-09-17T01:33:48.644924Z",
     "shell.execute_reply": "2020-09-17T01:33:48.645441Z"
    },
    "id": "Y7Bkx4c7yEq5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define the Keras TensorBoard callback, used for the animated, interactive tensorboard visualizatioon\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "#This should plot the exhaustive graph, but is a bit unreliable\n",
    "tf.keras.utils.plot_model(functional_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.print(\"processed_train_ds shape:\", processed_train_ds.take(0))\n",
    "functional_model.fit(processed_train_ds, epochs=5, callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6mNMfG6yEq5"
   },
   "source": [
    "Let's visualize our connectivity graph:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7975ec4232c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# do pre-processing of data separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m processed_test_ds = test_ds.map(\n\u001b[0m\u001b[0;32m      3\u001b[0m   lambda x, y: (\n\u001b[0;32m      4\u001b[0m       \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocesessing_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# do pre-processing of data separately\n",
    "processed_test_ds = test_ds.map(\n",
    "  lambda x, y: (\n",
    "      tf.cast(preprocesessing_model(x), dtype=tf.float32), \n",
    "      tf.cast(y, dtype=tf.float32)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.231471Z",
     "iopub.status.busy": "2020-09-17T01:33:52.230837Z",
     "iopub.status.idle": "2020-09-17T01:33:52.288853Z",
     "shell.execute_reply": "2020-09-17T01:33:52.289388Z"
    },
    "id": "T8N2uAdU2Cni",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "accuracy = functional_model.evaluate(processed_test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide x and y of test set\n",
    "x = []\n",
    "y_true = []\n",
    "\n",
    "for x_var, y_var in processed_test_ds:\n",
    "    x.append(x_var)\n",
    "    y_true.append(y_var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic metrics\n",
    "\n",
    "#skip NaN values here and in analysis later? TODO\n",
    "\n",
    "def get_true_pos(y, pred, th):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 1))\n",
    "\n",
    "\n",
    "def get_true_neg(y, pred, th):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 0))\n",
    "\n",
    "\n",
    "def get_false_neg(y, pred, th):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 1))\n",
    "\n",
    "\n",
    "def get_false_pos(y, pred, th):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 0))\n",
    "\n",
    "def get_acc(tp, tn, fp, fn):\n",
    "    total = sum([tp, tn, fp, fn])\n",
    "    correct = sum([tp, tn])\n",
    "    return correct / total\n",
    "\n",
    "def get_prevalence(tp, tn, fp, fn):\n",
    "    return (tp + fn) / (tp + tn + fp + fn)\n",
    "\n",
    "def get_specificity(tp, tn, fp, fn):\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def get_sensitivity(tp, tn, fp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def get_PPV(tp, tn, fp, fn):\n",
    "    return (tp / (tp + fp))\n",
    "\n",
    "def get_NPV(tp, tn, fp, fn):\n",
    "    return (tn / (fn + tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### based on coursera util.py for metrics\n",
    "\n",
    "\n",
    "def get_performance_metrics(y, pred, class_labels, threshold, \n",
    "                            tp=get_true_pos,\n",
    "                            tn=get_true_neg, fp=get_false_pos,\n",
    "                            fn=get_false_neg,\n",
    "                            acc=get_acc, prevalence=get_prevalence, spec=get_specificity,\n",
    "                            sens=get_sensitivity, ppv=get_PPV, npv=get_NPV, auc=None, f1=None):\n",
    "\n",
    "    columns = [\"Label\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
    "               \"Sensitivity\",\n",
    "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(class_labels)): ## i is the concerning class in each iteration\n",
    "        class_pred = pred[i]\n",
    "        #for separate classes:\n",
    "        #count_preds = len(class_pred) # the class was tried to predict as often as a prediction was made\n",
    "        #class_y = np.repeat(i, count_preds) # we filter for one class only anyway -> all the same\n",
    "        #for one class:\n",
    "        class_y = y[i]\n",
    "        ## get base metrics\n",
    "        true_p = round(tp(class_y, class_pred, threshold),3) if tp != None else \"Not Defined\"\n",
    "        true_n = round(tn(class_y, class_pred, threshold),3) if tn != None else \"Not Defined\"\n",
    "        false_p = round(fp(class_y, class_pred, threshold),3) if fp != None else \"Not Defined\"\n",
    "        false_n = round(fn(class_y, class_pred, threshold),3) if fn != None else \"Not Defined\"\n",
    "        \n",
    "        ## construct df for all data concerning class\n",
    "        row_data = {\n",
    "            \"Label\": class_labels[i],\n",
    "            \"TP\": true_p,\n",
    "            \"TN\": true_n,\n",
    "            \"FP\": false_p,\n",
    "            \"FN\": false_n,\n",
    "            \"Accuracy\": round(acc(true_p, true_n, false_p, false_n), 3) if acc != None else \"Not Defined\",\n",
    "            \"Prevalence\": round(prevalence(true_p, true_n, false_p, false_n), 3) if prevalence != None else \"Not Defined\",\n",
    "            \"Sensitivity\": round(sens(true_p, true_n, false_p, false_n), 3) if sens != None else \"Not Defined\",\n",
    "            \"Specificity\": round(spec(true_p, true_n, false_p, false_n), 3) if spec != None else \"Not Defined\",\n",
    "            \"PPV\": round(ppv(true_p, true_n, false_p, false_n), 3) if ppv != None else \"Not Defined\",\n",
    "            \"NPV\": round(npv(true_p, true_n, false_p, false_n), 3) if npv != None else \"Not Defined\",\n",
    "            \"AUC\": round(auc(class_y, class_pred), 3) if auc != None else \"Not Defined\",\n",
    "            \"F1\": round(f1(class_y, class_pred > threshold), 3) if f1 != None else \"Not Defined\",\n",
    "            \"Threshold\": round(threshold, 3)\n",
    "        }\n",
    "        tf.print(\"One row of metrics:\", row_data)\n",
    "        df = df.append(row_data, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_confidence_intervals(class_labels, statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    for i in range(len(class_labels)):\n",
    "        mean = statistics.mean(axis=1)[i]\n",
    "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
    "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
    "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_curve(gt, pred, target_names, curve='roc'):\n",
    "    for i in range(len(target_names)):\n",
    "        if curve == 'roc':\n",
    "            curve_function = roc_curve\n",
    "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
    "            xlabel = \"False positive rate\"\n",
    "            ylabel = \"True positive rate\"\n",
    "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(a, b, label=label)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "        elif curve == 'prc':\n",
    "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
    "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.step(recall, precision, where='post', label=label)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred = []\n",
    "stored_concepts = []\n",
    "stored_relevances = []\n",
    "\n",
    "for x_var in x:\n",
    "    aggregated, concepts, relevances = functional_model.predict(x_var)\n",
    "    y_pred.append(aggregated[0])\n",
    "    stored_concepts.append(concepts)\n",
    "    stored_relevances.append(relevances)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_array = np.array(y_true)\n",
    "class_labels = ['suicidal ideation']\n",
    "\n",
    "classification_thres = 0.5\n",
    "metrics = get_performance_metrics([y_true_array], [y_pred], class_labels, classification_thres)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#visualize model in an interactive way\n",
    "#sadly only works until the preprocessing layers are over\n",
    "# tensorboard sometimes thinks there still is an instance running when it is not\n",
    "# fix that by deleting the contents of this folder or your equivalent of it\n",
    "# C:\\Users\\deisl\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "\n",
    "\n",
    "# TODO reactivate this when tensorboard has been installed:\n",
    "\"\"\"\n",
    "%reload_ext tensorboard\n",
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "%tensorboard --logdir logs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMnTKaCZda",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "As the model contains all important parts, it should be able to work on any file of the right format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xkOlK8Zweeh"
   },
   "source": [
    "The model should be saved such that it can just be reloaded later.\\\n",
    "I will follow the tutorial [here](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:52.296839Z",
     "iopub.status.busy": "2020-09-17T01:33:52.296192Z",
     "iopub.status.idle": "2020-09-17T01:33:56.352943Z",
     "shell.execute_reply": "2020-09-17T01:33:56.352275Z"
    },
    "id": "QH9Zy1sBvwOH",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocesessing_model.save('preprocessing_model')\n",
    "functional_model.save('suicidal_ideation_model')\n",
    "reloaded_preprocessing = tf.keras.models.load_model('preprocessing_model')\n",
    "reloaded_model = tf.keras.models.load_model('suicidal_ideation_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D973plJrdwQ9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are just two things you need to do:\n",
    "\n",
    "1.   Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n",
    "2.   Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:33:56.360094Z",
     "iopub.status.busy": "2020-09-17T01:33:56.359400Z",
     "iopub.status.idle": "2020-09-17T01:33:56.669531Z",
     "shell.execute_reply": "2020-09-17T01:33:56.669015Z"
    },
    "id": "rKq4pxtdDa7i",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create a dataframe of all stored outputs from testing\n",
    "stored_aggregates = y_pred \n",
    "outputs = pd.DataFrame(list(zip(stored_aggregates, stored_concepts, stored_relevances)),\n",
    "                      columns =['aggregated', 'concepts', 'relevances'])\n",
    "\n",
    "# creating a legend that contains which output belongs to which input\n",
    "out_legend = []\n",
    "\n",
    "for header in output_sizes:\n",
    "    size = output_sizes[header]\n",
    "    for layer in range(0, size):\n",
    "        out_legend.append(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which sample to look at \n",
    "\n",
    "def investigate_sample(output):\n",
    "    aggregated = output['aggregated']\n",
    "    concept = output['concepts']\n",
    "    relevance = output['relevances']\n",
    "\n",
    "    relevance = np.array(relevance)\n",
    "    \n",
    "    # if I multiply 0 inputs with the relevances first, only relevant parts will be shown\n",
    "    binary_concepts = [0 if concept==0 else 1 for concept in concepts[0]]\n",
    "    binary_concepts = np.array(binary_concepts)\n",
    "    polarized_relevances = np.multiply(binary_concepts, relevance[0])\n",
    "\n",
    "    \n",
    "    filtered_output = [\n",
    "        (name,relevance) \n",
    "        for name, relevance in \n",
    "        zip(out_legend, polarized_relevances[0]) # TODO make this a dictionary\n",
    "        if not relevance==0\n",
    "    ]\n",
    "    \n",
    "    return aggregated, filtered_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_frame(df):\n",
    "    max_value = df.abs().max()\n",
    "    return df / max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \n",
    "# TODO filtered_output was a dictionary,\n",
    "# TODO and output was a param to investigate_sample()\n",
    "# one could loop through all outputs and make a dataframe with all the explanations\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "all_features = numerical_features + categorical_int_features + categorical_cols\n",
    "\n",
    "aggregates = []\n",
    "explanations = []\n",
    "low_prop_explanations = []\n",
    "high_prop_explanations = []\n",
    "\n",
    "for target_index in range(0, len(outputs.index)):\n",
    "    output = outputs.loc[[target_index]]\n",
    "    aggregated, explanation = investigate_sample(output)\n",
    "    aggregates.append(aggregated)\n",
    "    dict_exp = dict(explanation)\n",
    "    explanations.append(dict_exp)\n",
    "    \n",
    "    if aggregated[target_index] > classification_thres:\n",
    "        high_prop_explanations.append(dict_exp)\n",
    "    else:\n",
    "        low_prop_explanations.append(dict_exp)  \n",
    "\n",
    "#make  dataframes from records during loop\n",
    "explanations_frame = pd.DataFrame.from_records(explanations)\n",
    "explanations_frame.columns = all_features\n",
    "\n",
    "low_prop_explanations_frame = pd.DataFrame.from_records(low_prop_explanations)\n",
    "low_prop_explanations_frame.columns = all_features\n",
    "\n",
    "high_prop_explanations_frame = pd.DataFrame.from_records(high_prop_explanations)\n",
    "high_prop_explanations_frame.columns = all_features\n",
    "\n",
    "\n",
    "#calculate average values\n",
    "average_relevance = explanations_frame.mean(axis=0)\n",
    "\n",
    "average_relevance_low = low_prop_explanations_frame.mean(axis=0)\n",
    "\n",
    "average_relevance_high = high_prop_explanations_frame.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.print(\"The following frames have all been independently normalized and then sorted descendingly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.print(\"normalized average_relevance\\n\",normalize_frame(average_relevance).sort_values(ascending=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_average_relevance_low = normalize_frame(average_relevance_low)\n",
    "tf.print(\"normalized low probabilities average_relevance\\n\",normalized_average_relevance_low.sort_values(ascending=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_average_relevance_high = normalize_frame(average_relevance_high)\n",
    "tf.print(\"normalized high probabilities average_relevance\\n\",normalized_average_relevance_high.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_frame = normalized_average_relevance_high - normalized_average_relevance_low\n",
    "normalized_diff_frame = normalize_frame(differential_frame)\n",
    "sorted_normalized_diff_frame = normalized_diff_frame.sort_values(ascending=False)\n",
    "tf.print(\"normalized differences between high and low probabilities\\n\", sorted_normalized_diff_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the absence of a feature is actually not really taken into account explicitly.\n",
    "# however: if a certain feature is absent, that shifts the relevances of other features.\n",
    "# thus one can say that in absence of a specific feature, the other, shown features become relevant\n",
    "\n",
    "# this does make the average values less informative - the complex relationships are ignored\n",
    "# a decision tree would be more suited to look at those relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to inspect a specific sample:\n",
    "target_index = 80 # just enter the index of the sample\n",
    "output = outputs.loc[[target_index]]\n",
    "aggregated, explanation = investigate_sample(output)\n",
    "print(\n",
    "    \"This particular person had a %.1f percent probability \"\n",
    "    \"of experiencing suicidal ideation.\" % (100 * aggregated)\n",
    ")\n",
    "tf.print(\"The explanations are: \\n\", explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing everything for later\n",
    "\n",
    "#location\n",
    "directory = \"./saves/medium_high_risk\"\n",
    "\n",
    "# models:\n",
    "preprocesessing_model.save(directory+'preprocessing')\n",
    "functional_model.save(directory+'my_pet_classifier')\n",
    "\n",
    "# results:\n",
    "explanations_frame.to_pickle(directory+\"explanations_frame\")\n",
    "low_prop_explanations_frame.to_pickle(directory+\"low_prop_explanations_frame\")\n",
    "high_prop_explanations_frame.to_pickle(directory+\"high_prop_explanations_frame\")\n",
    "output.to_pickle(directory+\"output\")\n",
    "\n",
    "# evaluation\n",
    "metrics.to_pickle(directory+\"metrics\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing_layers.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
